// Package to provide functions for processing the "bigfile" used
// for the Parallelism and Concurrency presentation.
package bigfile

import (
	"io"
	"os"
	"fmt"
	"bufio"
	"strings"
	"log"
//	"os"
)

type ReadBufIOReader struct {
	io.ReadSeeker
	bufio.Reader
}

// Targetusername returns the value 
// for the key (k) in  the 
// settings.py file specified by the 
// argument s.
func Settings(s, k string) string {
	fp, err := os.Open(s)
	if err != nil {
		fmt.Printf("Could not open file %s.", s)
		panic(err)
	}
	defer fp.Close()
	r := bufio.NewReader(fp)

	for {
		line, isp, err := r.ReadLine()
		if err != nil {
			fmt.Print("Error reading file. Stderr=%s.  err=%d",os.Stderr, err)
            break
		}
		if isp {
            fmt.Fprintln(os.Stderr, "Line too long")
            break
        }
		l := string(line)
		if strings.HasPrefix(l, "#") {
			continue
		}
		if strings.Contains(l, k) {
			el := strings.Split(l, " ")
			return el[2]
		}
	}
	return ""
}

// Bigfilebrute reads a file, searchs for a string
// in each record.
// Returns the number of records read and matched.
func Brute(in,  query string) (int, int) {
	fin, err := os.Open(in)
	if err != nil {
		fmt.Printf("Could not open file %s.", in)
		panic(err)
	}
	defer fin.Close()

	fi, err := os.Stat(in)
	if err != nil{
		fmt.Printf("Could not stat %s\n", in)
		panic(err)
	}

//	r := bufio.NewReader(fin)
	size :=  int(fi.Blksize)
	r, err := bufio.NewReaderSize(fin, size)
	if err != nil {
		log.Fatal(err)
		panic(err)
	}
	recsread := 0
	recsmatch := 0
	for {
		line, isp, err := r.ReadLine()
		if err != nil {
			if err == os.EOF {
				break
			} else {
				fmt.Printf("Error reading file. Stderr=%s.  err=%d",os.Stderr, err)
				break
			}
		}
		if isp {
            fmt.Fprintln(os.Stderr, "Line too long")
            break
        }
		l := string(line)
		if strings.Contains(l, "ssbrtg") {
			//fmt.Println(l)
			//w.WriteString(l+"\n")
			recsmatch++
		}
        recsread++
	}
	return recsread, recsmatch
}

// Chunks breaks a file into n chunks.  Each chunk
// searches for key in a record.  
// Will suffixarray make the record search logrithmic?
func Chunks(in, key string, n int) (int, int) {
	fin, err := os.Open(in)
	if err != nil {
		fmt.Printf("Could not open file %s.", in)
		panic(err)
	}
	defer fin.Close()

//	r := bufio.NewReader(fin)
	recsread := 0
	recsmatch := 0

	fmt.Printf("Chunks: in=%s\n", in)
	fi, err := os.Stat(in)
	if err != nil{
		fmt.Printf("Could not stat %s\n", in)
		panic(err)
	}

	chunksize := fi.Size / int64(n)
	fmt.Printf("Chunks: chunksize=%d\n", chunksize)

	return recsread,recsmatch
}

// sizechunks divides the file into n chunks.
// Returns a map where each entry is
// map[start]=chunk_size.
func sizechunks(fh *File, fsize int64, numchunks) []int {

}